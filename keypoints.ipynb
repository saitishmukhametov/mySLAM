{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import FundamentalMatrixTransform, EssentialMatrixTransform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vid_path = 'test_freiburgrpy525.mp4'\n",
    "w = 1164\n",
    "h = 874\n",
    "F = 910\n",
    "\n",
    "def poseRt(R, t):\n",
    "  ret = np.eye(4)\n",
    "  ret[:3, :3] = R\n",
    "  ret[:3, 3] = t\n",
    "  return ret\n",
    "\n",
    "K = np.array([\n",
    "    [F, 0, w//2],\n",
    "    [0, F, h//2],\n",
    "    [0, 0, 1]])\n",
    "K_inv = np.linalg.inv(K)\n",
    "W = np.mat([[0,-1,0],[1,0,0],[0,0,1]],dtype=float)\n",
    "\n",
    "def normalize(x):\n",
    "  x = add_third(x)\n",
    "  return (K_inv @ x.T).T[:, 0:2]\n",
    "def denormalize(x):\n",
    "  return (K @ x)[:-1]\n",
    "\n",
    "def add_third(x):\n",
    "  return np.pad(x, pad_width = ((0,0), (0,1)) ,constant_values=1)\n",
    "\n",
    "def remove_third(x):\n",
    "  return x[:,[0,1]]\n",
    "\n",
    "def generate_frames(vid_path):\n",
    "    video = cv2.VideoCapture(vid_path, cv2.CAP_FFMPEG)\n",
    "    _, prev_frame = video.read()\n",
    "    for t in count():\n",
    "      ret, curr_frame = video.read()\n",
    "      if not ret:\n",
    "        break\n",
    "      yield prev_frame, curr_frame\n",
    "      prev_frame = curr_frame\n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def extractFeatures(frame):\n",
    "  orb = cv2.ORB_create()\n",
    "  # only works on b/w images\n",
    "  #pts = cv2.goodFeaturesToTrack(np.mean(frame,axis=2).astype(np.uint8), 3000, 0.05, minDistance=7)\n",
    "\n",
    "  pts = orb.detect(frame, None)\n",
    "  # we need kp class to feed it into ORB.compute to get descriptors\n",
    "  #kps = [cv2.KeyPoint(x=f[0][0], y=f[0][1], size=10) for f in pts]\n",
    "  kps = pts\n",
    "  kps, des = orb.compute(frame, kps)\n",
    "  return np.array([(kp.pt[0], kp.pt[1]) for kp in kps]), np.array(des)\n",
    "\n",
    "def bfmatcher(kps, dess):\n",
    "  bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "\n",
    "  # find closest descriptors between frames, hamming norm for ORB (BRIEF, BRISK...)\n",
    "  # they are binary string types\n",
    "  # L1, L2 for SIFT/SURF\n",
    "  matches = bf.knnMatch(dess[0], dess[1], k=2)\n",
    "  res = []\n",
    "  # DMatch obj: distance (the lower the better)\n",
    "  # trainIdx: index of the descriptor in train desc\n",
    "  # queryIdx: index of the descriptor in query desc\n",
    "  # imgIdx: index of the train image\n",
    "  for m,n in matches:\n",
    "    # Lowe's ratio test\n",
    "    # https://stackoverflow.com/questions/51197091/how-does-the-lowes-ratio-test-work\n",
    "    if m.distance < 0.70 * n.distance:\n",
    "        kp1 = kps[0][m.queryIdx]\n",
    "        kp2 = kps[1][m.trainIdx]\n",
    "        res.append((kp1, kp2))\n",
    "  res = np.array(res)\n",
    "  # prune the outliers by fitting\n",
    "  assert len(res)>=8, 'not enough points'\n",
    "  model, inliers = ransac((normalize(res[:,0]), normalize(res[:,1])),\n",
    "                          #FundamentalMatrixTransform, \n",
    "                          EssentialMatrixTransform,\n",
    "                          min_samples=8,\n",
    "                          residual_threshold=0.01, \n",
    "                          max_trials=100)\n",
    "\n",
    "  U, D, Vt = np.linalg.svd(model.params)\n",
    "\n",
    "  if np.linalg.det(U) < 0:\n",
    "    U *= -1.0\n",
    "  if np.linalg.det(Vt) < 0:\n",
    "    Vt *= -1.0\n",
    "  R1 = U @ W @ Vt\n",
    "  R2 = U @ W.T @ Vt\n",
    "  if abs(np.sum(R1.diagonal())-3) > abs(np.sum(R2.diagonal())-3):\n",
    "    R = R2\n",
    "  else: \n",
    "    R = R1\n",
    "  t = U[:, 2]\n",
    "  if t[2] < 0:\n",
    "    t *= -1\n",
    "  #pose = poseRt(R, t)\n",
    "  #print (t)\n",
    "  #print (f'good kps: {len(res[inliers])/len(res)*100:.2f}% out of {len(res)}')\n",
    "  return res[inliers,0], res[inliers,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_1 = None\n",
    "\n",
    "for i, (p, c) in enumerate(generate_frames(vid_path)):\n",
    "\n",
    "  if kps_1 is not None:\n",
    "    kps_1, des_1 = kps_2, des_2\n",
    "  else:\n",
    "    kps_1, des_1 = extractFeatures(p)\n",
    "  kps_2, des_2 = extractFeatures(c)\n",
    "\n",
    "  p1, p2 = bfmatcher([kps_1, kps_2], [des_1, des_2])\n",
    "  \n",
    "  for p in p2:\n",
    "    cv2.circle(c, (int(p[0]), int(p[1])), 1, (255,255,0))   \n",
    "  for k1, k2 in zip(p1, p2):\n",
    "    cv2.line(c, tuple(k1.astype(int)), tuple(k2.astype(int)), (0,200,200), 1)\n",
    "  cv2.imshow('v', c)\n",
    "  key = cv2.waitKey(1)\n",
    "  if key == ord('q'):\n",
    "    break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, list([3, 4]), 3, 4], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,[3,4]]\n",
    "b = [3,4]\n",
    "np.array([a,b]).flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4800ac1dff2557735fc0db4f1185ad1afe5e2a16df1d8003dabf188c324eab3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
